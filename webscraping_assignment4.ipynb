{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7a60573",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c7d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div/table[3]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516d73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div/table[3]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes \n",
    "try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2eb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div/table[3]/tbody/tr/td[3]\"):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70977286",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div/table[3]/tbody/tr/td[4]\"):\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c85118",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//div/table[3]/tbody/tr/td[5]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceafef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame \n",
    "Youtube_mostviewed=pd.DataFrame({\"Rank\":Rank[0:],\"Name\":Name[:],\"Artist\":Artist[:],\"Uplode_Date\":Upload_date[:],\"Views\":Views[:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a214f9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=Youtube_mostviewed.set_index('Rank')# making rank as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dffff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e69dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3256ecc8",
   "metadata": {},
   "source": [
    "(2)  Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.bcci.tv/.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b9bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fixture=driver.find_element_by_xpath(\"/html/body/footer/div/nav/ul/li[2]/ul/li[1]/a\")\n",
    "    fixture.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"Element not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16072a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty list to store data in it \n",
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date1=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath('//strong[@class=\"fixture__name fixture__name--with-margin\"]'):\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Match_title.append(\"NAN\") # will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68c5d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath('//span[@class=\"u-unskewed-text fixture__tournament-label u-truncated\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Series.append('NaN')# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath('//p[@class=\"fixture__additional-info\"]/span'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Place.append('NaN')# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath('//div/span[@class=\"fixture__date\"]|//div/span[@class=\"fixture__month\"]'):\n",
    "        Date1.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Date1.append('NaN')# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa044859",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52d7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(Date1),2):\n",
    "    Date.append(str(Date1[i])+'-'+Date1[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffdc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for i in driver.find_elements_by_xpath('//div/span[@class=\"fixture__time\"]'):\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    print(\"No such element present\")# will show if xpath changes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame \n",
    "Fixture=pd.DataFrame({\"Match_title\":Match_title[:],\"Series\":Series[:],\"Place\":Place[:],\"Date\":Date[:],\"Time\":Time[:]})\n",
    "Fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ccceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b182a",
   "metadata": {},
   "source": [
    "(3) Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677b6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "#Importing requests\n",
    "import requests\n",
    "# importing regex\n",
    "import re\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fd67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea87b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element_by_xpath(\"//*[@id=\"menu-item-3173\"]/a\")\n",
    "button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sbutton = driver.find_element_by_xpath(\"//*[@id=\"menu-item-4622\"]/a\")\n",
    "Sbutton.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_click = driver.find_element_by_xpath(\"//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a\")\n",
    "Tab_click.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    " #scraping Exception Name\n",
    " Name= driver.find_elements_by_xpath(\"//*[@id=\"post-1953\"]/div/div/table/tbody/tr[1]/th[1]\")\n",
    " for i in Name:\n",
    " Name.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb7329",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Exception Description\n",
    " Description = driver.find_elements_by_xpath(\"//*[@id=\"post-1953\"]/div/div/table/tbody/tr[1]/th[2]\")\n",
    " for i in Description:\n",
    " Description.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e135de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "df=pd.DataFrame({'Name':Name,\n",
    " 'Description':Description,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1928275",
   "metadata": {},
   "outputs": [],
   "source": [
    "diver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f5bc6",
   "metadata": {},
   "source": [
    "(5) Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60606bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://github.com/\")\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e2972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the Explore button\n",
    "button = driver.find_element_by_xpath(\"/html/body/div[1]/header/div[3]/nav/a[4]\")\n",
    "button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ce150",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on Trending button\n",
    "Ibutton = driver.find_element_by_xpath(\"//*[@id=\"js-pjax-container\"]/div[1]/nav/div/a[3]\")\n",
    "Ibutton.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make empty listes\n",
    "Repository title = []\n",
    "Repository description = []\n",
    "Contributors count = []\n",
    "Language used = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bda4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    " #scraping Repository title Details\n",
    "repository title= driver.find_elements_by_xpath(\"//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/h1/a/span\")\n",
    "for i in repository title:\n",
    "Repository title.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Repository description Details\n",
    " repository description = driver.find_elements_by_xpath(\"//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/p\")\n",
    "    for i in repository description:\n",
    "Repository description.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Contributors count Details\n",
    " contributors count = driver.find_elements_by_xpath(\"//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/div[2]/span[1]/span[2]]\")\n",
    " for i in contributors count:\n",
    "Contributors count.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6367b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping Language used Details\n",
    " language used = driver.find_elements_by_xpath(\"//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/div[2]/span[1]/span[2]\")\n",
    " for i in language used:\n",
    "Language used.append(i.text)\n",
    " time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f513947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    " df=pd.DataFrame({'Repository title':Repository title,\n",
    " 'Repository description ':Repository description,\n",
    " 'Contributors count':Contributors count,\n",
    " 'Language used':Language used })\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a322bcc",
   "metadata": {},
   "source": [
    "(4) Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP\n",
    "D) GSDP\n",
    "E) Share\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa6179",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on Economy button\n",
    "driver.find_element_by_xpath(\"//div[@class='navbar']/div[2]/button\").click()\n",
    "\n",
    "# clicking on India\n",
    "driver.find_element_by_xpath(\"//div[@class='dropdown-content']/a[3]\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "# clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac08e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDP_billion = []\n",
    "\n",
    "# scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "    \n",
    "# scraping State\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "    \n",
    "\n",
    "    \n",
    "# scraping GSDP at current price (19-20)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[3]\"):\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP1.append(\"_\")\n",
    "    \n",
    "# scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "    \n",
    "# scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "    \n",
    "# scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements_by_xpath(\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"_\")\n",
    "    \n",
    "    # creating DataFrame from the scraped data\n",
    "GDP = pd.DataFrame({})\n",
    "GDP['Rank'] = Rank\n",
    "GDP['State'] = State\n",
    "GDP['GSDP at current price (19-20)'] = GSDP1\n",
    "GDP['GSDP at current price (18-19)'] = GSDP2\n",
    "GDP['Share (18-19)'] = Share\n",
    "GDP['GDP($ billion)'] = GDP_billion\n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6852db",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614e9afb",
   "metadata": {},
   "source": [
    "(6) Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b2694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on option button\n",
    "charts=driver.find_element_by_xpath(\"//a[@class='header__main-link header__main-link--charts']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad5f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name =[]\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []\n",
    "\n",
    "# getting urls for top 100 songs\n",
    "urls = driver.find_element_by_xpath(\"//li[@class='header__submenu__list__element']//a\")\n",
    "page_url = urls.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(4)\n",
    "\n",
    "# scraping data of song names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\"):\n",
    "    Song_Name.append(i.text)\n",
    "    \n",
    "# scraping data of artist names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "    Artist_Name.append(i.text)\n",
    "    \n",
    "# scraping data of last week ranks\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "    Last_week_rank.append(i.text)\n",
    "    \n",
    "\n",
    "# scraping data of peak ranks\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "    Peak_rank.append(i.text)       \n",
    "    \n",
    "    \n",
    "# scraping data of weeks on board\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "    Weeks_on_board.append(i.text)\n",
    "    # creating dataframe for scraped data\n",
    "billiboard = pd.DataFrame({})\n",
    "billiboard['Name'] = Song_Name\n",
    "billiboard['Artist'] = Artist_Name\n",
    "billiboard['Last Week Rank'] = Last_week_rank\n",
    "billiboard['Peak Rank'] = Peak_rank\n",
    "billiboard['Weeks on board'] = Weeks_on_board\n",
    "billiboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca40fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e97011",
   "metadata": {},
   "source": [
    "(7) Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cd7914",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching urls to navigate recruiter page\n",
    "recruiter = driver.find_element_by_xpath(\"//a[@title='Search Recruiters']\")\n",
    "page_url = recruiter.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d121c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching search button, sending keys and clicking on it\n",
    "search = driver.find_element_by_xpath(\"//div[@class='inpWrap']//input\")\n",
    "search.send_keys(\"Data Science\")\n",
    "\n",
    "btn = driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []\n",
    "\n",
    "# scraping data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fl ellipsis']\"):\n",
    "    Name.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# scraping data of Designation\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='ellipsis clr']\"):\n",
    "    Designation.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# scraping data of Company Name\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]/a[2]\"):\n",
    "    Company.append(i.text)\n",
    "time.sleep(3)\n",
    "\n",
    "# scraping data of Skills\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='hireSec highlightable']\"):\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        Skills.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Skills.append('-')\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# scraping data of Location\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='vcard']//p[1]/span/small\"):\n",
    "    try:\n",
    "        if i.text == \"Not Specified\": raise NoSuchElementException\n",
    "        Location.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Location.append('-')\n",
    "time.sleep(3)\n",
    "\n",
    "# creating dataframe for scraped data\n",
    "Naukri = pd.DataFrame({})\n",
    "Naukri['Name'] = Name[:49]\n",
    "Naukri['Designation'] = Designation[:49]\n",
    "Naukri['Company'] = Company[:49]\n",
    "Naukri['Skills'] = Skills[:49]\n",
    "Naukri['Location'] = Location[:49]\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1098b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028c43a9",
   "metadata": {},
   "source": [
    "(8) Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4bbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Book_name = []\n",
    "Author_name = []\n",
    "Volumes_sold = []\n",
    "Publisher = []\n",
    "Genre = []\n",
    "\n",
    "\n",
    "# scraping book names data\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr//td[2]\"):\n",
    "    Book_name.append(i.text)\n",
    "    \n",
    "# scraping author names data\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr//td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# scraping data of volumes sold\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr//td[4]\"):\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraping data of publisher names\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr//td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraping  data of genre\n",
    "for i in driver.find_elements_by_xpath(\"//tbody//tr//td[6]\"):\n",
    "    Genre.append(i.text) \n",
    "    \n",
    "# creating dataframe for scraped data\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['Book Name'] = Book_name\n",
    "Novels['Author'] = Author_name\n",
    "Novels['Volume sold'] = Volumes_sold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1440b8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e751277",
   "metadata": {},
   "source": [
    "(9) Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97504995",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b823549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "\n",
    "# scraped data of Names\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Year span\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Genre\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Run time\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "# scraped data of Ratings\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "# scraped data of Votes\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text) \n",
    "    \n",
    "    \n",
    "# creating dataframe for scraped data\n",
    "TV_Series = pd.DataFrame({})\n",
    "TV_Series['Name'] = Name\n",
    "TV_Series['Year Span'] = Year_span\n",
    "TV_Series['Genre'] = Genre\n",
    "TV_Series['Run Time'] = Run_time\n",
    "TV_Series['Ratings'] = Ratings\n",
    "TV_Series['Votes'] = Votes\n",
    "TV_Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eae646",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a07b5",
   "metadata": {},
   "source": [
    "(10) Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13fe1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\91832\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element_by_xpath(\"//tbody[1]//tr/td[2]/span[2]/a\")\n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching page urls of all datasets\n",
    "view_list = driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")\n",
    "list_url = view_list.get_attribute(\"href\")\n",
    "driver.get(list_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching urls for each dataset\n",
    "dataset_url = driver.find_elements_by_xpath(\"//p[@class='normal']//b/a\")\n",
    "\n",
    "urls = []\n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []\n",
    "\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping  Dataset name\n",
    "    try:\n",
    "        dataset_name = driver.find_element_by_xpath(\"//span[@class='heading']\")\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    " # scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping Task\n",
    "    try:\n",
    "        task = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    " # scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # scraping No of Instances\n",
    "    try:\n",
    "        instances = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    " # scraping No of Arrtibutes\n",
    "    try:\n",
    "        attribute = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    time.sleep(3)\n",
    "    \n",
    "    \n",
    "    # scraping Year\n",
    "    try:\n",
    "        year = driver.find_element_by_xpath(\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for scraped data\n",
    "ML = pd.DataFrame({})\n",
    "ML['Data Name'] = Data_name \n",
    "ML['Data Type '] = Data_type\n",
    "ML['Task '] = Task \n",
    "ML['Attribute Type '] = Attribute_type \n",
    "ML['No of Instance '] = No_of_instances\n",
    "ML['No of Attributes '] = No_of_attributes \n",
    "ML['Year '] = Year \n",
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b61cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67175240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
